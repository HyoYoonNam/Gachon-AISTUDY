{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGndpPW3gpCNbJJ/CimZyk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/Pytorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tensor data type\n",
        "* 기본적으로 Machine Learning에서는 연산 속도를 위해서 array data type을 사용한다.\n",
        "* 이때 Numpy에서는 CPU를 사용하여 array를 연산하기 때문에 DL 수준의 dataset에 대해서 연산하기에는 시간이 많이 소요된다.\n",
        "* Tensor는 GPU 연산을 지원하는 array이다. pytorch에서는 이를 사용한다."
      ],
      "metadata": {
        "id": "ANng_D3WI0dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 0. Convert list(python) or ndarray(numpy) to tensor(pytorch)\n",
        "\n",
        "cf. [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)\n",
        "\n",
        "```\n",
        "torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
        "```\n",
        "\n",
        "**Parameters**  \n",
        "* __data__ - Can be a list, tuple, Numpy `ndarray`, scalar, ...  \n",
        "\n",
        "**Keyword Arguements**  \n",
        "* __dtype__(`torch.dtype`, optinal) - the desired data type of returned tensor. default라면, 원본 데이터 타입\n",
        "* __device__(`torch.device`, optional) - the device of the constructed tensor. defalut라면, 'cpu' 사용, 'cuda'로 설정 시 gpu 사용 가능.\n",
        "* __requires_grad__(_bool_, optional)\n",
        "* **pin_memory**(*bool*, optional)"
      ],
      "metadata": {
        "id": "pIpjnr_OKcXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# case1-1. python list_int\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_default = torch.tensor(data)\n",
        "x_int = torch.tensor(data, dtype=int)\n",
        "x_int64 = torch.tensor(data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int ßßdata type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5m9i8faGUA-",
        "outputId": "e3d0e2e7-26e6-4631-97ff-6d7ff18e70dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case1-2. python list_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(data, dtype=float)\n",
        "x_float32 = torch.tensor(data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(data, dtype=torch.float64)\n",
        "x_double = torch.tensor(data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI5yDY6SRf4",
        "outputId": "ab224380-c715-44b3-dcd6-396d33aa2838"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2. numpy to tensor\n",
        "# 결론적으로는 list to tensor나 ndarray to tensor나 동일하다.\n",
        "import numpy as np\n",
        "np_data = np.array(data)\n",
        "print(type(np_data))\n",
        "print(np_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBreb74oTSDe",
        "outputId": "c45af325-dd72-466d-f18b-014eb6574e59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-1. numpy ndarray_int\n",
        "x_default = torch.tensor(np_data)\n",
        "x_int = torch.tensor(np_data, dtype=int)\n",
        "x_int64 = torch.tensor(np_data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(np_data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVc_mJQ5T75Z",
        "outputId": "2e5e1459-7989-45fa-e63a-becbc40fd417"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-2. numpy ndarray_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(np_data, dtype=float)\n",
        "x_float32 = torch.tensor(np_data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(np_data, dtype=torch.float64)\n",
        "x_double = torch.tensor(np_data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ipKbkVUK1g",
        "outputId": "838606b5-659f-4cf8-be06-0c81130b15f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-1. How to use GPU"
      ],
      "metadata": {
        "id": "mpTv64UyUl-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_default.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogrRdUj0QKq7",
        "outputId": "c613ae6a-15cf-4bf3-88c5-cca25a30895a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uiGPsRvIpfH",
        "outputId": "fde9a03e-4103-4e71-c6fa-6ff70b822d26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.device('cuda:1000000'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzgiPZNOVE36",
        "outputId": "e43b20f3-77d1-4958-b7d5-cc914d4d314b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# CPU에 텐서 생성 (기본값)\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(tensor_cpu.device)  # 출력: cpu\n",
        "\n",
        "# GPU에 텐서 생성 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(tensor_gpu.device)  # 출력: cuda:0\n",
        "\n",
        "# 기존 텐서를 다른 장치로 이동\n",
        "tensor_cpu_to_gpu = tensor_cpu.to('cuda')  # CPU에서 GPU로 이동\n",
        "print(tensor_cpu_to_gpu.device)  # 출력: cuda:0\n",
        "\n",
        "tensor_gpu_to_cpu = tensor_gpu.to('cpu')  # GPU에서 CPU로 이동\n",
        "print(tensor_gpu_to_cpu.device)  # 출력: cpu"
      ],
      "metadata": {
        "id": "OUDAKK0sVV3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# CPU에 텐서 생성 (기본값)\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(tensor_cpu.device)  # 출력: cpu\n",
        "\n",
        "# GPU에 텐서 생성 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(tensor_gpu.device)  # 출력: cuda:0\n",
        "\n",
        "# CPU와 GPU 텐서 출력\n",
        "print(\"Tensor on CPU:\", tensor_cpu)\n",
        "print(\"Tensor on GPU:\", tensor_gpu if torch.cuda.is_available() else \"CUDA not available\")\n"
      ],
      "metadata": {
        "id": "Fg2AWj3DVWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] [머신러닝 파이토치 다루기 기초 - WikiDocs](https://wikidocs.net/book/9379)  \n",
        "[2] [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)"
      ],
      "metadata": {
        "id": "RydV314IFN30"
      }
    }
  ]
}