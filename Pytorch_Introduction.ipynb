{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ANng_D3WI0dP",
        "pIpjnr_OKcXM",
        "mpTv64UyUl-U",
        "l7FN9ytvt_Mo",
        "y4Max_dxE53G"
      ],
      "authorship_tag": "ABX9TyPXeyS0DWe/B5IEIpMRgmp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/Pytorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tensor data type\n",
        "* 기본적으로 Machine Learning에서는 연산 속도를 위해서 array data type을 사용한다.\n",
        "* 이때 Numpy에서는 CPU를 사용하여 array를 연산하기 때문에 DL 수준의 dataset에 대해서 연산하기에는 시간이 많이 소요된다.\n",
        "* Tensor는 GPU 연산을 지원하는 array이다. pytorch에서는 이를 사용한다.  \n",
        "\n",
        "> 왜 Numpy ndarray가 아닌, Pytorch tensor를 사용하는지에 대한 자세한 이유들은 이후 실습 과정을 통해서 자연스럽게 알 수 있을 것으로 판단된다."
      ],
      "metadata": {
        "id": "ANng_D3WI0dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 0. Convert list(python) or ndarray(numpy) to tensor(pytorch)\n",
        "\n",
        "cf. [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)\n",
        "\n",
        "```\n",
        "torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
        "```\n",
        "\n",
        "**Parameters**  \n",
        "* __data__ - Can be a list, tuple, Numpy `ndarray`, scalar, ...  \n",
        "\n",
        "**Keyword Arguements**  \n",
        "* __dtype__(`torch.dtype`, optinal) - the desired data type of returned tensor. default라면, 원본 데이터 타입\n",
        "* __device__(`torch.device`, optional) - the device of the constructed tensor. defalut라면, 'cpu' 사용, 'cuda'로 설정 시 gpu 사용 가능.\n",
        "* __requires_grad__(_bool_, optional)\n",
        "* **pin_memory**(*bool*, optional)"
      ],
      "metadata": {
        "id": "pIpjnr_OKcXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# case1-1. python list_int\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_default = torch.tensor(data)\n",
        "x_int = torch.tensor(data, dtype=int)\n",
        "x_int64 = torch.tensor(data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int ßßdata type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5m9i8faGUA-",
        "outputId": "49a37e7a-9939-4e95-de8f-a08092c461ea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case1-2. python list_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(data, dtype=float)\n",
        "x_float32 = torch.tensor(data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(data, dtype=torch.float64)\n",
        "x_double = torch.tensor(data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI5yDY6SRf4",
        "outputId": "c0d6edb7-c90d-480c-c818-167c25ab9df7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2. numpy to tensor\n",
        "# 결론적으로는 list to tensor나 ndarray to tensor나 동일하다.\n",
        "import numpy as np\n",
        "np_data = np.array(data)\n",
        "print(type(np_data))\n",
        "print(np_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBreb74oTSDe",
        "outputId": "18328c1b-6d90-4910-eeaa-20c20e07e474"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-1. numpy ndarray_int\n",
        "x_default = torch.tensor(np_data)\n",
        "x_int = torch.tensor(np_data, dtype=int)\n",
        "x_int64 = torch.tensor(np_data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(np_data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVc_mJQ5T75Z",
        "outputId": "7b6e6867-6e55-4bd4-ec73-d10079089055"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-2. numpy ndarray_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(np_data, dtype=float)\n",
        "x_float32 = torch.tensor(np_data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(np_data, dtype=torch.float64)\n",
        "x_double = torch.tensor(np_data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ipKbkVUK1g",
        "outputId": "2466ca58-be92-4929-cb05-68de2e7ae8b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 1. How to use GPU(CUDA)"
      ],
      "metadata": {
        "id": "mpTv64UyUl-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch를 실행중인 device에서 cuda(gpu)를 사용할 수 있는지 확인\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uiGPsRvIpfH",
        "outputId": "3d1ac54f-abc8-4230-f3e1-fd5c2f1c241e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor() 등으로 tensor를 생성할 때는 default로 'cpu'를 사용\n",
        "print(x_default.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogrRdUj0QKq7",
        "outputId": "238f01eb-30c3-418f-d0ad-7b601054e9eb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU에 텐서 생성 (default)\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0]) # same as the below\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0], device='cpu') # same as the above\n",
        "print(tensor_cpu.device) # cpu\n",
        "\n",
        "# GPU에 텐서 생성 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(tensor_gpu.device)  # cuda:0\n",
        "else:\n",
        "    print('Error: CUDA not available')"
      ],
      "metadata": {
        "id": "OUDAKK0sVV3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc6ba11-33e8-48d8-fdad-8cc0dad16998"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 텐서를 다른 장치로 이동\n",
        "tensor_cpu_to_gpu = tensor_cpu.to('cuda')  # CPU에서 GPU로 이동\n",
        "print(tensor_cpu_to_gpu.device)  # cuda:0\n",
        "\n",
        "tensor_gpu_to_cpu = tensor_gpu.to('cpu')  # GPU에서 CPU로 이동\n",
        "print(tensor_gpu_to_cpu.device)  # cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDyidBPUtRe-",
        "outputId": "19c3c9b6-1299-4687-83db-da9f0059480a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 2. How to create the tensor"
      ],
      "metadata": {
        "id": "l7FN9ytvt_Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. non-random values\n",
        "\n",
        "# 1-dim tensor\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# 2-dim tensor\n",
        "y = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(y)\n",
        "print()\n",
        "\n",
        "# 3-dim tensor, every element is 0\n",
        "z = torch.zeros((2, 3, 4))\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "# 4-dim tensor, every element is 1\n",
        "w = torch.ones((2, 2, 2, 2))\n",
        "print(w)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abESN7TfvWa6",
        "outputId": "e5a4b3b5-b641-421b-b1f4-d5fe7a60b06a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "\n",
            "tensor([[[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. use the Distribution for random values\n",
        "\n",
        "# case1. Uniform Distribution\n",
        "# create 3 by 2 tensor, each element is randomed between [0, 1)\n",
        "x = torch.rand((3, 2))\n",
        "print(x)\n",
        "\n",
        "# case 2. Normal Distribution\n",
        "# create 2 by 3 tensor, each element is randomed,\n",
        "# following normal distribution, mean = 0 and deviation = 1\n",
        "y = torch.randn((2, 3))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWoDyzKmxmVp",
        "outputId": "81e0b936-351e-4d32-9245-60d120633605"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2631, 0.4802],\n",
            "        [0.3996, 0.2660],\n",
            "        [0.7379, 0.3503]])\n",
            "tensor([[-0.5243, -1.8474,  0.2482],\n",
            "        [ 2.3250, -1.4715, -0.3961]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. randomly-uninitialized values(it is fast because non-intialize)\n",
        "\n",
        "x = torch.empty(2, 3) # default dtype is float32\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "\n",
        "y = torch.empty(2, 3, dtype=torch.int64) # you can use anoter dtype\n",
        "print(y)\n",
        "print(y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQCmICdR2j7y",
        "outputId": "9708c8af-6188-45af-b41d-4068f549ba8c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.6691e-33,  3.0709e-41, -2.4794e-32],\n",
            "        [ 3.0709e-41,  7.3790e-01,  3.5029e-01]])\n",
            "torch.float32\n",
            "tensor([[137421895495040,  94126540939792,              32],\n",
            "        [             80,  94140637894011,             129]])\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 3. Convet ndarray to tensor by `.from_numpy()` and `.tensor()`\n",
        "**1. 0.**에서는 `.tensor()`를 사용해서 numpy array를 tensor로 변환했다.  \n",
        "`.from_numpy()`로도 변환이 가능한데, 둘의 차이를 알아보자.\n",
        "```\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print(type(x_np), type(x_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```\n",
        "\n",
        "```\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print(type(x_np), type(y_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```"
      ],
      "metadata": {
        "id": "pibQHdZj4_sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `.tensor()`는 call by value 개념이다\n",
        "# 즉 기존의 ndarray를 copy해서 memory에 별도로 생성한다\n",
        "# 따라서 tensor와 ndarray는 서로 독립적이다\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꿔도 ndarray에는 영향을 주지 않는다\n",
        "x_tensor[0] = -1\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysOhzuft7VL_",
        "outputId": "d61a5152-a4f0-41a2-d370-02864415a3c9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: 1 tensor: tensor(-1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `.from_numpy()`는 call by reference 개념이다\n",
        "# 이미 ndarray가 할당된 memory adress가 존재할 때,\n",
        "# `.from_numpy()`로 생성된 tensor 객체는 ndarray와 동일한 address를 referencing한다\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꾸면 ndarray에도 영향을 준다\n",
        "y_tensor[0] = -1\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# 반대의 경우에도 마찬가지\n",
        "y_np[1] = -2\n",
        "print('ndarray:', y_np[1], 'tensor:', y_tensor[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCYv34sf8XbU",
        "outputId": "e6ff1dfe-b9cf-4205-f266-d98d56f11a18"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: -1 tensor: tensor(-1)\n",
            "ndarray: -2 tensor: tensor(-2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 3.(검증) memory address 확인을 통한 검증"
      ],
      "metadata": {
        "id": "L1Be-F_h-xqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음에 내가 아는 선에서 시도한 검증은 다음과 같이 `id()`를 사용하는 것이었다\n",
        "print(id(x_np), id(x_tensor)) # predict: different  | actual: different\n",
        "print(id(y_np), id(y_tensor)) # predict: different  | actual: different"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSj3agKg9TON",
        "outputId": "4a2c188d-7da2-41ea-a6a7-996a1b2ef36e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137417068456976 137417068960144\n",
            "137417068457264 137417068962864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> numpy와 tensor 모두 memory address에 value 자체를 보관하고, **그 address를 참조하는 객체**를 생성하는 것이다.  \n",
        "\n",
        "> 즉 value 자체의 address와 참조하는 객체의 address 두 가지가 존재하는 상태이다.  \n",
        "이때 `id()`는 후자를 리턴한다.  \n",
        "\n",
        "> (다음 cell) 다음과 같이 **value 자체의 address**를 확인할 수 있다."
      ],
      "metadata": {
        "id": "ynWrjz6h_jpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict: different    | actual: different\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr())\n",
        "print()\n",
        "# predict: same         | actual: same\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8e-XY2I-dKK",
        "outputId": "278936ce-36b9-4175-a256-a5952387c637"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94126506241600\n",
            "94126539663808\n",
            "\n",
            "94126506241792\n",
            "94126506241792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 4. Convert tensor to ndarray\n",
        "tensor 객체를 Numpy ndarray로 변환하는 method는 `tensor.numpy()` method 뿐이다.  \n",
        "\n",
        "또한 `tensor.numpy()`는 copy하지 않고, 무조건 share한다."
      ],
      "metadata": {
        "id": "rZACgFWBBhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_npnp = x_tensor.numpy()\n",
        "print(type(x_npnp))\n",
        "\n",
        "y_npnp = y_tensor.numpy()\n",
        "print(type(y_npnp))\n",
        "\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr()) # x_np를 copy한 x_tensor\n",
        "print(x_npnp.__array_interface__['data'][0]) # x_tensor를 share한 x_npnp\n",
        "print()\n",
        "\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr()) # y_np를 share한 y_tensor\n",
        "print(y_npnp.__array_interface__['data'][0]) # y_tensor를 share한 y_npnp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib9mK0z3EAKa",
        "outputId": "32d95eba-825e-40fc-e76e-c76e2e632c65"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "94126506241600\n",
            "94126539663808\n",
            "94126539663808\n",
            "\n",
            "94126506241792\n",
            "94126506241792\n",
            "94126506241792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. tensor attributes\n",
        "Pytorch의 **tensor object**는 많은 attributes를 갖지만, 그 중에서 자주 쓸 만한 것들에 대해서만 다루겠다.  \n",
        "1. __dtype__\n",
        "    * data type\n",
        "2. __device__\n",
        "    * tensor object가 위치한 device(cpu, gpu)\n",
        "3. __size__\n",
        "    * tensor object의 shape\n",
        "4. __ndim__\n",
        "    * tensor object의 dimension\n",
        "5. __numel()__\n",
        "    * tensor object의 전체 elements 수"
      ],
      "metadata": {
        "id": "y4Max_dxE53G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'dtype', 'device'는 위에서 이미 다뤘으므로 생략함\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "y = x.view(2, 2) # same as reshape in Numpy\n",
        "\n",
        "print(y) # [[1, 2], [3, 4]]\n",
        "print(x.size(), y.size()) # [4] [2, 2] # same as shape in Numpy\n",
        "print(x.ndim, y.ndim) # 1 2\n",
        "print(x.numel(), y.numel()) # 4 4 # same as size in Numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITA9FadGGdxU",
        "outputId": "7e0b5046-3fe1-4cc9-b791-a97dc58e829a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([4]) torch.Size([2, 2])\n",
            "1 2\n",
            "4 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. tensor calculation\n",
        "Numpy와 마찬가지로 **Broadcasting**이 적용된다."
      ],
      "metadata": {
        "id": "C1iKeN1tQqSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# addition in tensor\n",
        "a = torch.tensor([[1, 2,], [3, 4]])\n",
        "b = torch.tensor([[5, 6], [7, 8]])\n",
        "var_add = a + b\n",
        "print(var_add)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SJbIwaCQ3-D",
        "outputId": "d7727d92-a89c-4529-dccb-9067cc388b23"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6,  8],\n",
            "        [10, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction in tensor\n",
        "var_sub = a - b\n",
        "print(var_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MLiKCNROrx",
        "outputId": "467dce09-4b7a-45b7-eadd-707a089146fe"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4, -4],\n",
            "        [-4, -4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply in tensor\n",
        "var_mul = a * b\n",
        "print(var_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11E85enDRxva",
        "outputId": "158a4168-8f50-461e-8455-9ce936797847"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5, 12],\n",
            "        [21, 32]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide in tensor\n",
        "var_div = a / b\n",
        "print(var_div)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0hBCwF_vJe0",
        "outputId": "7d898514-a3e5-4477-ac58-eb4ab8b36f82"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, particularly in linear algebra, matrix multiplication is a binary operation that produces a matrix from two matrices. For matrix multiplication, **the number of columns in the first matrix** must be equal to **the number of rows in the second matrix**. The resulting matrix, known as the matrix product, has **the number of rows of the first** and **the number of columns of the second** matrix. The product of matrices A and B is denoted as AB.  \n",
        "* $C_{11} = A.row_1 * B.col_1$\n",
        "* $C_{12} = A.row_1 * B.col_2$\n",
        "* $C_{21} = A.row_2 * B.col_1$\n",
        "* $C_{22} = A.row_2 * B.col_2$"
      ],
      "metadata": {
        "id": "2pjvDp8cxVUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication\n",
        "var_matrix_mul = torch.mm(a, b)\n",
        "print(var_matrix_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH7kdxk1vjto",
        "outputId": "a684ea4f-a980-4953-f7ef-a199c87cae5b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, the dot product or scalar product is an algebraic operation that **takes two equal-length sequences of numbers** (usually coordinate vectors), and **returns a single number**. It is often called the inner product."
      ],
      "metadata": {
        "id": "R3nyTxlczpjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product in tensor\n",
        "var_dot_prod = torch.dot(a[0], a[1])\n",
        "print(var_dot_prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvCd0Kc6vjzo",
        "outputId": "cafdad64-98bf-4b70-cf67-e9e839ac4524"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max value\n",
        "#                  col1    col2\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.tensor([[4, 3], [2, 1]])\n",
        "var_max_a = torch.max(a)\n",
        "var_max_b = torch.max(b)\n",
        "var_max_ab = torch.max(a, b)\n",
        "print(var_max_a, var_max_b) # 4 4\n",
        "# column끼리 비교해서 max를 리턴함\n",
        "# max_col1, max_col2\n",
        "print(var_max_ab) # [4, 3], [3, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quuNPJ1I0KfI",
        "outputId": "cefe6395-f618-4127-96b1-8fd99844f173"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4) tensor(4)\n",
            "tensor([[4, 3],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensionality reduction; 차원 축소\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# dim=0, 하나의 matrix의 각 row를 개별 matrix로 취급하여 dot product를 수행하는 개념\n",
        "var_reduce_dim0 = torch.sum(a, dim=0)\n",
        "# dim=1\n",
        "var_reduce_dim1 = torch.sum(a, dim=1)\n",
        "\n",
        "print(var_reduce_dim0)\n",
        "print(var_reduce_dim1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2xVK-e-1d_q",
        "outputId": "20b48adc-b3e1-4fff-afab-86fb8be4bb77"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 6])\n",
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "# parameter is input tensor, first dim and second dim to transposed\n",
        "var_trans = torch.transpose(a, 0, 1)\n",
        "print(var_trans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk_3fp5m2mVq",
        "outputId": "8ef55918-056a-415b-b840-5ee89e59acdd"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 3],\n",
            "        [2, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing\n",
        "#                   0       1       2\n",
        "#                  0  1    0  1    0  1\n",
        "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "var_index = a[1, 0]\n",
        "print(var_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6G94DUj3m33",
        "outputId": "c42a26c4-c7fe-4046-fcb6-7079eb67c760"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "var_slice_1 = a[:, :1] # for the all rows, col1 전까지\n",
        "             # '까지'니까 selected element가 1개라는 것이 보장되지 않음\n",
        "             # 따라서 2dim으로 리턴\n",
        "var_slice_2 = a[:, 1] # for the all rows, col1만\n",
        "            # '만'이니까 selected element가 1개라는 것이 보장됨\n",
        "            # 따라서 1dim으로 리턴\n",
        "print(var_slice_1)\n",
        "print(var_slice_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoKXSINZ4AMf",
        "outputId": "5b904cff-4fd3-45a5-b0a8-80c254f7332c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [3],\n",
            "        [5]])\n",
            "tensor([2, 4, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boolean indexing\n",
        "a = torch.tensor([1, 2, 3, 4, 5])\n",
        "# statement 만족하면 True, 아니면 False가 되고 True인 index의 elements만 리턴\n",
        "var_bool = a[a > 3]\n",
        "print(var_bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc1QK6dE5WUa",
        "outputId": "c4ea0f3d-5993-407e-c9d5-1a173aecd90f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] [머신러닝 파이토치 다루기 기초 - WikiDocs](https://wikidocs.net/book/9379)  \n",
        "[2] [PyTorch Tensor vs NumPy Array - GeeksforGeeks](https://www.geeksforgeeks.org/pytorch-tensor-vs-numpy-array/)  \n",
        "[3] [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)  "
      ],
      "metadata": {
        "id": "RydV314IFN30"
      }
    }
  ]
}