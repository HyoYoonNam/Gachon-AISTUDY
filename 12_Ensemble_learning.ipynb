{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6uhan9zzzsXeb8J0pg3gD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/12_Ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 예제11까지 다뤄온 Data\n",
        "## 0. 1. Structured data; 정형 데이터\n",
        "CSV, Database, Excel 등으로 다룰 수 있는 data를 의미한다.  \n",
        "대부분의 데이터는 Structured data에 속한다.\n",
        "또한 예제11까지 다룬 ML algorithm들은 Structured data에 적용하기 적합하다.  \n",
        "이때 Structured data를 다루는 대부분의 경우에서 가장 뛰어난 성과를 내는 algorithm이 있는데, ***Ensemble learning**이다.  \n",
        "> *In statistics and machine learning, __ensemble methods__ use mulitple learning algorithms to obatin better perdictive performeance than could be obtained from any of the constituent learning algorithms alone. - [Wikipedia](https://en.wikipedia.org/wiki/Ensemble_learning)\n",
        "\n",
        "## 0. 2. Unstructured data; 비정형 데이터\n",
        "텍스트 데이터, 사진, 디지털 음악 등이 여기에 속한다.\n",
        "> Unstructured data의 경우 규칙성을 찾기가 어려워서 기존의 machine learning 방법으로는 model을 만들기가 까다롭다.  \n",
        "때문에 나중에 배울 **neural network algorithm**을사용한다.\n",
        "\n",
        "## 0. 3. Ensemble methods\n",
        "본 예제 **12_Ensemble-learning.ipynb**에서는 다음과 같은 ensemble methods에 대해서 다룬다.  \n",
        "* #1. Random Forest\n",
        "* #2. Extra Trees\n",
        "* #3. Gradient Boosting\n",
        "* #4. Histogram-based Gradient Boosting"
      ],
      "metadata": {
        "id": "WUanMNImdF0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Random Forest; 랜덤 포레스트"
      ],
      "metadata": {
        "id": "JETL8XSWr26T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('http://bit.ly/wine_csv_data')"
      ],
      "metadata": {
        "id": "7SOba8DEr72X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC9wgmrMsZdR",
        "outputId": "c35da693-efae-4bac-ea05-cffbddfa083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6497 entries, 0 to 6496\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   alcohol  6497 non-null   float64\n",
            " 1   sugar    6497 non-null   float64\n",
            " 2   pH       6497 non-null   float64\n",
            " 3   class    6497 non-null   float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 203.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "351C5rI7seAV",
        "outputId": "ea9f86b0-4064-4e1b-a743-072025b16da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           alcohol        sugar           pH        class\n",
              "count  6497.000000  6497.000000  6497.000000  6497.000000\n",
              "mean     10.491801     5.443235     3.218501     0.753886\n",
              "std       1.192712     4.757804     0.160787     0.430779\n",
              "min       8.000000     0.600000     2.720000     0.000000\n",
              "25%       9.500000     1.800000     3.110000     1.000000\n",
              "50%      10.300000     3.000000     3.210000     1.000000\n",
              "75%      11.300000     8.100000     3.320000     1.000000\n",
              "max      14.900000    65.800000     4.010000     1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cab0fc58-364f-46dd-9bb3-20167007b86e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>sugar</th>\n",
              "      <th>pH</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "      <td>6497.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.491801</td>\n",
              "      <td>5.443235</td>\n",
              "      <td>3.218501</td>\n",
              "      <td>0.753886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.192712</td>\n",
              "      <td>4.757804</td>\n",
              "      <td>0.160787</td>\n",
              "      <td>0.430779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.500000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>3.110000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10.300000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11.300000</td>\n",
              "      <td>8.100000</td>\n",
              "      <td>3.320000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.900000</td>\n",
              "      <td>65.800000</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cab0fc58-364f-46dd-9bb3-20167007b86e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cab0fc58-364f-46dd-9bb3-20167007b86e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cab0fc58-364f-46dd-9bb3-20167007b86e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88dcef79-9108-4c78-8c7b-fa9810e96201\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88dcef79-9108-4c78-8c7b-fa9810e96201')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88dcef79-9108-4c78-8c7b-fa9810e96201 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"wine\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2293.7220855129385,\n        \"min\": 1.192711748870993,\n        \"max\": 6497.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10.491800831152839,\n          10.3,\n          6497.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2292.6192015521087,\n        \"min\": 0.6,\n        \"max\": 6497.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.443235339387409,\n          3.0,\n          6497.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2296.039173424216,\n        \"min\": 0.16078720210398764,\n        \"max\": 6497.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.2185008465445586,\n          3.21,\n          6497.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2296.7745419728712,\n        \"min\": 0.0,\n        \"max\": 6497.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7538864091118977,\n          1.0,\n          0.4307786597787077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = wine.drop('class', axis=1).to_numpy()\n",
        "y = wine['class'].to_numpy()\n",
        "print(X[:3])\n",
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXCaSz19sh57",
        "outputId": "ca234d8f-2134-48ad-fe7f-8ef04f35dadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.4  1.9  3.51]\n",
            " [9.8  2.6  3.2 ]\n",
            " [9.8  2.3  3.26]]\n",
            "[0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BiW9gDz4st74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "\n",
        "# case1. test score만 리턴\n",
        "# scores = cross_validate(rf, X_train, y_train,\n",
        "#                         n_jobs=-1)\n",
        "# print(np.mean(scores['test_score']))\n",
        "# print(scores)\n",
        "\n",
        "# case2. train score도 리턴\n",
        "# 여기서의 test는 validation set임을 유의\n",
        "scores = cross_validate(rf, X_train, y_train,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u432AHxLtqvR",
        "outputId": "5bb8122a-2158-44bb-b1d6-e41b10d2c115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n",
            "{'fit_time': array([2.08594203, 2.17877221, 1.83536553, 1.90284824, 1.263165  ]), 'score_time': array([0.13418102, 0.15252733, 0.15143609, 0.11618233, 0.12137032]), 'test_score': array([0.88461538, 0.88942308, 0.90279115, 0.88931665, 0.88642926]), 'train_score': array([0.9971133 , 0.99663219, 0.9978355 , 0.9973545 , 0.9978355 ])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 cell을 보면 overfitting된 것을 확인할 수 있다.  \n",
        "본 예제에서는 RF algorithm의 성능을 높이는 것이 주 목적이 아니라, 학습 자체가 목적이기 때문에 추가적인 handling은 하지 않는다.\n",
        "\n",
        "Random Forest는 결국 Decision Tree의 ensemble이므로 기본적으로 `DecisionTreeClassifier()`에서의 주요 *parameters를 그대로 사용한다.\n",
        "> `criterion`, `max_depth`, `max_features`, `min_samples_split`, `min_impurity_decrease`, `min_samples_leaf` 등.  \n",
        "또한 Decision Tree의 큰 장점 중 하나인 `feature_importances_` attribute도 계산한다.  \n",
        "\n",
        "> 이때 RF에서의 `feature_importances_` attribute의 값은 RF를 이루는 각 DT의 `feature_importances_` attribute 값을 취합한 것이다."
      ],
      "metadata": {
        "id": "DLVy-KiEvSEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X_train, y_train)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWchmaO7whqK",
        "outputId": "be99b4c1-7d08-45e2-8a3b-b27fdf550781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞선 **10_Decision-Tree.ipynb** 예제에서의 `dt.feature_importances_`는 각각 다음과 같았다.  \n",
        "```[0.12345626 0.86862934 0.0079144  ]```  \n",
        "둘을 비교해보면 RF에서의 `feature_importances_` attribute의 값이 보다 고르게 퍼진 것을 확인할 수 있다.  \n",
        "> 기본적으로 DT에서는 **_entire features 중에서_** child node의 impurity decrease 정도를 가장 크게 만드는 feature를 선택한다.  \n",
        "또한 대부분의 경우에서는 entire features가 동등하게 중요하지는 않다(ex. wine의 경우에는 sugar만 중요하고, 나머지 features는 사실상 의미가 없었다).  \n",
        "이 때문에 대부분의 node에서는 most important feature(sugar)에 대해서만 나눠지게 되는데 이는 overfitting을 유발할 수 있다.  \n",
        "\n",
        "> 기본적으로 RF에서는 먼저 각 node마다 entire features 중에 일부를 일단 고른다(default는 **squared roof** of number of entire features 즉, 전체 특성 수가 9개라면 그 제곱근인 3개를 각 node마다 고름, 또한 소수점의 경우 내림).  \n",
        "  >> 그리고 **_선택된 일부의 features 중에서_** child node의 impurity decrease 정도를 가장 크게 만드는 feature를 선택한다.  \n",
        "  따라서 most importance feature라고 하더라도, '일부'에 선택되지 못한다면 사용되지 못한다.  \n",
        "  따라서 그 하위의 importance를 가진 features에게 기회가 주어진다.  \n",
        "  따라서 하나의 feature에 과도하게 집중하지 않고 좀 더 많은 features를 사용하여 훈련하게 된다."
      ],
      "metadata": {
        "id": "mgiok5mqw09k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* * *\n",
        "`RandomForestClassifier()` 클래스는 **자체적으로 model을 평가하는 점수**를 얻을 수도 있다.  \n",
        "RF에서는 **중복을 허용하는** bootstrap sample을 사용한다.  \n",
        "따라서 확률적으로 어떤 sample은 중복으로 선택될 것이고, ***어떤 sample은 아예 선택되지 않을 것**이다.  \n",
        "> *이를 __$OOB^{out of bag}$ sample__이라고 한다.  \n",
        "\n",
        "즉 RF를 이루는 각 DT는 bootstrap sample로 training되고, training된 DT를 OOB로 평가할 수 있다(validation set과 유사한 개념)."
      ],
      "metadata": {
        "id": "zTe2Z5jw3dEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default, oob_score=False. n_jobs=1\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKJoVoC43q6U",
        "outputId": "61f4c7af-a066-4585-eb19-cbef1717da5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 현재까지 **X_test, y_test는 사용한 적이 없음**을 명심하자.\n",
        "\n",
        "> `np.mean(scores['test_score']`는 X_test가 아니라, RF(또는 DT)에 대해서 수행하는 cross_validation(k-fold)에서의 test 즉, **validation set에 대한 score**이다.  \n",
        ">> k-fold cross validation에서는 sub_train이 train이고 validation이 test 개념이기 때문\n",
        "\n",
        "> `rf.oob_score_`는 **OOB sample에 대한 score**이다."
      ],
      "metadata": {
        "id": "MkDEcxO25SW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Extra Trees; 엑스트라 트리\n",
        "Extra Trees는 다음과 같은 특징을 갖는다.  \n",
        "* __DT 및 RF와 유사하게__ DT가 제공하는 대부분의 parameters 지원\n",
        "* __RF와 유사하게__ entire features 중에서 일부 특성을 random하게 선택  \n",
        "  - RF는 일부 특성 몇 개를 random하게 선택하고, 그 중에서 최적의 분할을 찾는다.\n",
        "  - ET는 entire features 중에 1개를 random하게 선택해서 분할한다.\n",
        "* __RF와는 다르게__ bootstrap sample을 사용하지 않는다  \n",
        "  즉, 각 Decision Tree를 만들 때 train set의 전체를 사용한다.  \n",
        "* __RF와는 다르게__ ***가장 좋은 분할**을 찾는 것이 아니라 무작위로 분할한다.  \n",
        "  > *child node의 impurity decrease 정도가 가장 크게끔 분할되는 것을 의미한다.  \n",
        "    `ExtraTreesClassifier()`는 각 DT에 대해서 `splitter` parameter를  'random'으로 설정한다.  \n",
        "    다음 cell을 보면 DT의 default splitter는 'best'임을 확인할 수 있다.  \n",
        "\n",
        "  - 무작위로 분할한다면 각 node가 최적으로 분할되지 않기 때문에 **model performance는 낮아**질 수 있다.\n",
        "  - 다만 특정 feature가 과도하게 선택되지 않기 때문에 **overfitting을 방지**할 수 있다.\n",
        "  - 또한 경우의 수를 나열하고 그 중에서 최적의 node를 찾는 방식이 아니라, random하게 node를 분할하기 때문에 **연산 과정이 크게 감소**한다.\n"
      ],
      "metadata": {
        "id": "zf4Um47g7XWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "print(dt.splitter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyUVPwxRmR-s",
        "outputId": "ee5cc690-78fd-4661-9aa9-4a819815295b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, X_train, y_train,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "print('RF에서의 score는 다음과 같았다.\\n0.9973541965122431 0.8905151032797809')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuj3q8KFm_b0",
        "outputId": "9b91257c-ab93-47f9-defd-9e65f9b83545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n",
            "RF에서의 score는 다음과 같았다.\n",
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* RF에서는 entire features 중에서 일부를 랜덤하게 선택하고, 그 중에서 최적의 분할을 찾는 방식으로 DT에서 most importance feature에 과도하게 치중되는 문제를 해소했다.  \n",
        "* ET에서는 random하게 node를 분할하는 방식으로 위 문제도 해소하고, 연산 속도도 크게 감소시켰다."
      ],
      "metadata": {
        "id": "I_D0OK1sq8VQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "et.fit(X_train, y_train)\n",
        "print('alcohol\\t\\tsugar\\tpH')\n",
        "print(et.feature_importances_)\n",
        "print('DT에서의 feature_importances_는 다음과 같았다.\\n[0.12345626 0.86862934 0.0079144 ]')\n",
        "print('RF에서의 feature_importances_는 다음과 같았다.\\n[0.23167441 0.50039841 0.26792718]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAZP0pf0onZM",
        "outputId": "8f54e39b-398d-4168-eccb-2684b3c05b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alcohol\t\tsugar\tpH\n",
            "[0.20183568 0.52242907 0.27573525]\n",
            "DT에서의 feature_importances_는 다음과 같았다.\n",
            "[0.12345626 0.86862934 0.0079144 ]\n",
            "RF에서의 feature_importances_는 다음과 같았다.\n",
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Gradient Boosting; 그레이디언트 부스팅\n",
        "scikit-learn에서 제공하는 Gradient Boosting은 기본적으로 `max_depth=3`, `n_estimators=100`, `learning_rate=0.1`이다.  \n",
        "즉 X와 y가 존재할 때 Model 1은 X에 대한 y를 prediction하고, 이를 실제 y와 비교한다. 이때 두 값의 차이를 **residual; 잔차**라고 한다.  \n",
        "Model 1에서의 Residual 1은 Model 2의 y가 되고, Model 2는 y를 prediction하고, 이를 실제 y와 비교한다.  \n",
        "(이하 반복 ...)  \n",
        "> 따라서 Model n+1을 수행하기 위해서는 Model n이 존재해야 하는 순차적인 학습이다."
      ],
      "metadata": {
        "id": "GuGREnwAtDWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, X_train, y_train,\n",
        "                        return_train_score=True, n_jobs=1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6B_W1v7Hhju",
        "outputId": "3785e0c5-d6a4-4aea-864a-d8ec62b943a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 cell과 같이 max_depth가 얕은 DT를 여러 개 사용하기 때문에 overfitting이 거의 발생하지 않는다.  \n",
        "\n",
        "~~Increase: To make something larger in amount, number, or degree.~~  \n",
        "~~Enhance: To improve the quality, value, or attractiveness of something.~~  \n",
        "**How to enhance the performance of a gradient boosting model**  \n",
        "  * Increase the value of the `learning_rate` parameter.\n",
        "  * Increase the number of trees(the `n_estimators` parameter)."
      ],
      "metadata": {
        "id": "9PVxifdEH8Hh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 gradient boosting은 순차적 학습을 하기 때문에 `n_jobs` parameter가 존재하지 않음을 확인할 수 있다."
      ],
      "metadata": {
        "id": "CJ6M55ZENPNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# error 확인용\n",
        "print(gb.n_jobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "Do13fUp0NWZz",
        "outputId": "a4263546-2f19-495c-ac00-9357a62b181c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GradientBoostingClassifier' object has no attribute 'n_jobs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-69e6028f07a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GradientBoostingClassifier' object has no attribute 'n_jobs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,\n",
        "                                random_state=42)\n",
        "scores = cross_validate(gb, X_train, y_train,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jobrr3XRMLpa",
        "outputId": "61368f67-3562-4958-bc8c-0727501aae16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 cell을 보면 `n_estimators`와 `learning_rate` parameter의 조정으로 model performance가 향상된 것을 확인할 수 있다."
      ],
      "metadata": {
        "id": "40drxVZXMrp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(X_train, y_train)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgwQvPd6NgSm",
        "outputId": "12c22ccb-065a-4fdb-ec81-f14697e073bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정리하자면, gradient boosting은 다음과 같은 특징을 갖는다.  \n",
        "* 병렬처리가 어렵다. `n_jobs` parameter가 존재하지 않는다. training이 오래 걸린다.\n",
        "* `n_estimator`, `learning_rate` 등의 parameter의 수가 다른 ensemble algorithm에 비해 많기 때문에 hyperparameter tuning 또한 더 어렵다."
      ],
      "metadata": {
        "id": "yhaRZ33lNlXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Histogram-based Gradient Boosting; 히스토그램 기반 그레이디언트 부스팅\n",
        "Histogram-based Gradient Boosting은 다음과 같은 특징을 갖는다.  \n",
        "* 먼저, 입력된 특성(일반적으로 Continuous)을 256개의 discrete한 구간으로 나눈다.  \n",
        "ex. 입력의 최소 value가 1, 최대 value가 1,000이라면 구간 1 = 1 ~ 4, 구간 2 = 5 ~ 8, ... 구간 256 = 997 ~ 1000\n",
        "* 각 구간에 속하는 데이터의 수를 구한다(Histogram 형식).\n",
        "* node를 분할할 때 256개의 구간들에 대해서 각 구간을 기준으로 분할했을 때의 loss function 감소량을 계산하고, 감소량을 가장 크게 만드는 구간을 기준으로 분할한다.\n",
        "  - 구간 1을 기준으로 나눴을 때의 loss function 감소량 = 2,  \n",
        "    구간 15를 기준으로 나눴을 때의 loss function 감소량 = 10이고 가장 큰 값이라면, 구간 15를 기준으로 분할한다.\n",
        "  - 즉 데이터 분포가 얼마나 넓은지에 상관없이 256번만 계산하면 되기 때문에 매우 빠르게 연산할 수 있다.\n",
        "\n",
        "> 엄밀히 말하자면, 256개 구간 중 한 개의 구간은 missing value가 존재했을 때 넣어두는 구간이다. 따라서 missing value에 대한 전처리를 따로 하지 않아도 되는 편리함이 있다.  \n",
        "일단은 이 정도로만 알아두면 되겠다."
      ],
      "metadata": {
        "id": "tNe4keCZN_MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, X_train, y_train,\n",
        "                        return_train_score=True) # gradient boosting의 일종이기 때문에 n_jobs 없다.\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPWzPCeAS61J",
        "outputId": "294a3f8c-c860-44c9-b577-82ba71fc2353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 cell을 보면 미세하지만 앞선 GradientBoosting보다 train_score는 감소하고, test_score는 증가한 것을 확인할 수 있다."
      ],
      "metadata": {
        "id": "0b7UB82xUpOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* * *"
      ],
      "metadata": {
        "id": "9-KiT8ZeVZJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.fit(X_train, y_train)\n",
        "print(hgb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ANkxoRXxVISC",
        "outputId": "324e0298-63c7-4c69-ace6-c5703d710790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'HistGradientBoostingClassifier' object has no attribute 'feature_importances_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-78292f6b3f7a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'HistGradientBoostingClassifier' object has no attribute 'feature_importances_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(위 cell 참고)또한 scikit-learn의 histogram-based gradient boosting(classifier, regression)에는 특성 중요도를 계산한 값이 보관되는 `feature_importances_` attribute가 존재하지 않는다.  \n",
        "* **continuous value**를 **discrete value**로 변환했기 때문에 기존의 특성 중요도 계산 방식으로는 정확하게 특성 중요도를 계산해낼 수 없다.\n",
        "* 이에 대한 대안으로 `permutation_importance()`를 사용하여 특성 중요도를 계산할 수 있다.  \n",
        "\n",
        "> 위 함수는 다음과 같이 작동한다.  \n",
        "  * histogram-based gradient boosting을 사용해서 train set으로 model을 training하고, test set으로 model performance를 측정한다.\n",
        "  * test set에서 각 data instances들의 $ x_1 $값을 shuffling한다.  \n",
        "    이때 다른 features의 값은 변경하지 않는다.\n",
        "  * __$ x_1 $ 값만 shuffling된 permutated_1 test set__으로 model performance를 측정한다(일반적으로 감소할 것이다).\n",
        "  * performance 감소 정도가 크다면 특성 중요도 값을 높게 평가하고, 아니라면 낮게 평가한다.\n",
        "  * 위 과정을 __$ x_2 $ 값만 shuffling된 permutated_2 test set__, __$ x_3 $ 값만 shuffling된 permutated_3 test set__, ...에 대해서 반복한다.\n",
        "  * 그러면 $ x_j $ 값이 shuffling 되었을 때의 performance 감소량을 비교하여 특성 중요도 값을 산정할 수 있다."
      ],
      "metadata": {
        "id": "qcZhzuG7VdGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(X_train, y_train)\n",
        "# defalut, n_repeats=5. shuffle 횟수\n",
        "result = permutation_importance(hgb, X_train, y_train,\n",
        "                                n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXxYBaojYozv",
        "outputId": "ec48a3c2-2b71-4a66-d4bf-462ac5e6a03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# permutation_importance 객체에는 중요도 array, mean, std가 있음\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELPf1aNDkGX2",
        "outputId": "33c240d2-2d11-4983-873c-0624ce1df46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'importances_mean': array([0.08876275, 0.23438522, 0.08027708]), 'importances_std': array([0.00382333, 0.00401363, 0.00477012]), 'importances': array([[0.08793535, 0.08350972, 0.08908986, 0.08312488, 0.09274581,\n",
            "        0.08755051, 0.08601116, 0.09601693, 0.09082163, 0.09082163],\n",
            "       [0.22782374, 0.23590533, 0.23936887, 0.23436598, 0.23725226,\n",
            "        0.23436598, 0.23359631, 0.23398114, 0.23994612, 0.22724649],\n",
            "       [0.08581874, 0.08601116, 0.08062344, 0.07504329, 0.08427939,\n",
            "        0.07792957, 0.07234943, 0.07465846, 0.08139311, 0.08466423]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 cell을 보면 test set의 경우에도 sugar feature($x_2$)의 중요도가 높게 평가됨을 확인할 수 있다."
      ],
      "metadata": {
        "id": "YJMnAiNJkuD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = permutation_importance(hgb, X_test, y_test,\n",
        "                                n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmupc1Uuki64",
        "outputId": "2dfb6229-7058-4371-88aa-a7cb462c5996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 최종적으로 test set에 대한 model performance를 확인하자."
      ],
      "metadata": {
        "id": "TPnxBHTAkDDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "8YlzX5FslE33",
        "outputId": "3d90e81d-e25f-4487-e2a0-fc71010fd3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}