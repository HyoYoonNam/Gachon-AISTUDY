{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRzXFtnE6HKE+a4WgzgbfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/PyTorch_2_tensor%2C_storage%2C_stride.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tensor\n",
        "tensor는 결국 Numpy ndarray라고 생각하면 된다(완전히 동일한 개념은 아니다).  \n",
        "즉 n-dimensional array라는 것인데, 결국 memory상에서 연산하기 위해서는 1-dimensional의 vector array가 되어야 한다."
      ],
      "metadata": {
        "id": "y8S-hp-pXyUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# storage\n",
        "n-dimensional array를 1-dimensional의 vecter array로 변환한 것이 **storage**이다."
      ],
      "metadata": {
        "id": "9-7OnXfHYZjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 2 by 3의 2-dimensional tensor\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(tensor.shape)\n",
        "print(tensor)\n",
        "\n",
        "# tensor가 memory상에서 연산되기 위해서는 storage로 변환되어야 한다\n",
        "storage = tensor.storage()\n",
        "# 이때 storage 자체는 tensor 객체가 아니고, tensor 객체의 데이터가 저장된 array이다\n",
        "# 따라서 .shape나 .size() 등의 tensor 객체에 대한 메서드 사용 불가\n",
        "print(f'storage size: {len(storage)}')\n",
        "# print(storage.shape) # error occured!\n",
        "print(storage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUfVaKa1Yl_J",
        "outputId": "f79b6d7a-2ade-4650-96fd-58f19cb8915c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "storage size: 6\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            " 6\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stride"
      ],
      "metadata": {
        "id": "iK8_zYSXacs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transposed_tensor\n",
        "tensor_T = torch.tensor([[1, 4], [2, 5], [3, 6]])\n",
        "storage_T = tensor_T.storage()\n",
        "print(tensor_T.shape)\n",
        "print(tensor_T)\n",
        "print(f'storage_T size: {len(storage_T)}')\n",
        "print(storage_T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asXUKxU6afkn",
        "outputId": "015123d0-ab94-40a8-d5e1-4dfded076a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "storage_T size: 6\n",
            " 1\n",
            " 4\n",
            " 2\n",
            " 5\n",
            " 3\n",
            " 6\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(위 cell)  \n",
        "`storage`와 `storage_T`는 언뜻 보면 동일하게 보인다.  \n",
        "\n",
        "하지만 이 둘은 각각 2 by 3의 `tensor`와 3 by 2의 `tensor_T`로부터 비롯된 storage이기 때문에 다른 것이다.  \n",
        "> 컴퓨터는 이 둘을 어떻게 다른 것으로 구분할까?  \n",
        "정답은 `stride`에 있다."
      ],
      "metadata": {
        "id": "tTxh_JCXc9w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결론부터 먼저 확인\n",
        "print(storage == storage_T) # Output: False\n",
        "print(tensor.stride(), tensor_T.stride())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kRIU7MZdnWK",
        "outputId": "15c0a260-d399-4c47-eb42-e75a22ffbdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "(3, 1) (2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그렇다면 `stride`란 무엇일까?  \n",
        "\n",
        "[torch.Tensor.stride — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.stride.html)\n",
        "> Stride is the jump necessary to go from one element to the next one in the specified dimension dim. A tuple of all strides is returned when no argument is passed in. Otherwise, an integer value is returned as the stride in the particular dimension dim.\n",
        "\n",
        "이를 풀어서 설명하자면 다음과 같다.  \n",
        "* * *\n",
        "**`tensor`의 경우:**  \n",
        "\n",
        "| tensor | column1 | column2 | column3 |\n",
        "| :---: | :---: | :---: | :---: |\n",
        "| row1 | 1 | 2 | 3 |\n",
        "| row2 | 4 | 5 | 6 |\n",
        "\n",
        "이를 row 순서대로 나열하면 다음과 같다.  \n",
        "\n",
        "| offset | 0 | 1 | 2 | 3 | 4 | 5 |\n",
        "| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| value | 1 | 2 | 3 | 4 | 5 | 6 |\n",
        "\n",
        "1. row1의 first index인 `1`에서 row2의 first index인 `4`로 이동하기 위해서는 `3번의 jump`가 필요하다.  \n",
        "    * `jump1`: offset 0 → 1 (value: `1` → `2`)\n",
        "    * `jump2`: offset 1 → 2 (value: `2` → `3`)\n",
        "    * `jump3`: offset 2 → 3 (value: `3` → `4`)\n",
        "\n",
        "2. column1의 first index인 `1`에서 column2의 first index인 `2`로 이동하기 위해서는 `1번의 jump`가 필요하다.  \n",
        "    * `jump1`: offset 0 → 1 (value: `1` → `2`)\n",
        "\n",
        "따라서, `tensor.stride()` = (3, 1)\n",
        "\n",
        "* * *\n",
        "**`tensor_T`의 경우:**  \n",
        "\n",
        "| tensor_T | column1 | column2 |\n",
        "| :---: | :---: | :---: |\n",
        "| row1 | 1 | 4 |\n",
        "| row2 | 2 | 5 |\n",
        "| row3 | 3 | 6 |\n",
        "\n",
        "이를 row 순서대로 나열하면 다음과 같다.  \n",
        "\n",
        "| offset | 0 | 1 | 2 | 3 | 4 | 5 |\n",
        "| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| value | 1 | 4 | 2 | 5 | 3 | 6 |\n",
        "\n",
        "1. row1의 first index인 `1`에서 row2의 first index인 `2`로 이동하기 위해서는 `2번의 jump`가 필요하다.  \n",
        "    * `jump1`: offset 0 → 1 (value: `1` → `4`)\n",
        "    * `jump2`: offset 1 → 2 (value: `4` → `2`)\n",
        "\n",
        "2. column1의 first index인 `1`에서 column2의 first index인 `4`로 이동하기 위해서는 `1번의 jump`가 필요하다.  \n",
        "    * `jump1`: offset 0 → 1 (value: `1` → `4`)\n",
        "\n",
        "따라서, `tensor_T.stride()` = (2, 1)"
      ],
      "metadata": {
        "id": "DlPtktbheShH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.stride(), tensor_T.stride())"
      ],
      "metadata": {
        "id": "0qcmxJqmfUlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25973d9-0eef-4c0a-a0d2-1bb95f265d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1) (2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# stride(보충)\n",
        "사실 tensor를 row 순서대로 나열할 때는 다음과 같이 `torch.flatten(Tensor)` 메서드를 사용할 수 있다."
      ],
      "metadata": {
        "id": "yVdSI4Dpk1dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_flatten = torch.flatten(tensor)\n",
        "tensor_T_flatten = torch.flatten(tensor_T)\n",
        "print(tensor_flatten)\n",
        "print(tensor_T_flatten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U3vaVW4lAHF",
        "outputId": "a6a23253-00c4-47f8-b4da-a0057108d0a2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6])\n",
            "tensor([1, 4, 2, 5, 3, 6])\n"
          ]
        }
      ]
    }
  ]
}
