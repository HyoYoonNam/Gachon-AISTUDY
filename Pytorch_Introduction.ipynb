{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pIpjnr_OKcXM",
        "l7FN9ytvt_Mo"
      ],
      "authorship_tag": "ABX9TyOYkesjLPgS0h5Bk7JDesqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/Pytorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tensor data type\n",
        "* 기본적으로 Machine Learning에서는 연산 속도를 위해서 array data type을 사용한다.\n",
        "* 이때 Numpy에서는 CPU를 사용하여 array를 연산하기 때문에 DL 수준의 dataset에 대해서 연산하기에는 시간이 많이 소요된다.\n",
        "* Tensor는 GPU 연산을 지원하는 array이다. pytorch에서는 이를 사용한다.  \n",
        "\n",
        "> 왜 Numpy ndarray가 아닌, Pytorch tensor를 사용하는지에 대한 자세한 이유들은 이후 실습 과정을 통해서 자연스럽게 알 수 있을 것으로 판단된다."
      ],
      "metadata": {
        "id": "ANng_D3WI0dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 0. Convert list(python) or ndarray(numpy) to tensor(pytorch)\n",
        "\n",
        "cf. [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)\n",
        "\n",
        "```\n",
        "torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
        "```\n",
        "\n",
        "**Parameters**  \n",
        "* __data__ - Can be a list, tuple, Numpy `ndarray`, scalar, ...  \n",
        "\n",
        "**Keyword Arguements**  \n",
        "* __dtype__(`torch.dtype`, optinal) - the desired data type of returned tensor. default라면, 원본 데이터 타입\n",
        "* __device__(`torch.device`, optional) - the device of the constructed tensor. defalut라면, 'cpu' 사용, 'cuda'로 설정 시 gpu 사용 가능.\n",
        "* __requires_grad__(_bool_, optional)\n",
        "* **pin_memory**(*bool*, optional)"
      ],
      "metadata": {
        "id": "pIpjnr_OKcXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# case1-1. python list_int\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_default = torch.tensor(data)\n",
        "x_int = torch.tensor(data, dtype=int)\n",
        "x_int64 = torch.tensor(data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int ßßdata type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5m9i8faGUA-",
        "outputId": "cacd3742-b227-4744-e99c-ec7aec7fe472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case1-2. python list_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(data, dtype=float)\n",
        "x_float32 = torch.tensor(data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(data, dtype=torch.float64)\n",
        "x_double = torch.tensor(data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI5yDY6SRf4",
        "outputId": "17ac5af7-873f-44d8-f1e2-d00c6daa8697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2. numpy to tensor\n",
        "# 결론적으로는 list to tensor나 ndarray to tensor나 동일하다.\n",
        "import numpy as np\n",
        "np_data = np.array(data)\n",
        "print(type(np_data))\n",
        "print(np_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBreb74oTSDe",
        "outputId": "01c1748a-0fdb-4d86-ad39-fdabfdecd195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-1. numpy ndarray_int\n",
        "x_default = torch.tensor(np_data)\n",
        "x_int = torch.tensor(np_data, dtype=int)\n",
        "x_int64 = torch.tensor(np_data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(np_data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVc_mJQ5T75Z",
        "outputId": "21af3280-4289-48c1-b723-28c9e3de3cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-2. numpy ndarray_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(np_data, dtype=float)\n",
        "x_float32 = torch.tensor(np_data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(np_data, dtype=torch.float64)\n",
        "x_double = torch.tensor(np_data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ipKbkVUK1g",
        "outputId": "8099cd54-a997-43ef-d22b-c7a69dbfe6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 1. How to use GPU(CUDA)"
      ],
      "metadata": {
        "id": "mpTv64UyUl-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch를 실행중인 device에서 cuda(gpu)를 사용할 수 있는지 확인\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uiGPsRvIpfH",
        "outputId": "a5daa306-971d-41b8-926a-d1ac1cb49a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor() 등으로 tensor를 생성할 때는 default로 'cpu'를 사용\n",
        "print(x_default.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogrRdUj0QKq7",
        "outputId": "6a2f07db-eeaf-4e0e-e778-4decefdae3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU에 텐서 생성 (default)\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0]) # same as the below\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0], device='cpu') # same as the above\n",
        "print(tensor_cpu.device) # cpu\n",
        "\n",
        "# GPU에 텐서 생성 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(tensor_gpu.device)  # cuda:0\n",
        "else:\n",
        "    print('Error: CUDA not available')"
      ],
      "metadata": {
        "id": "OUDAKK0sVV3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6655ff3-2d7b-4eed-81b9-03ec9779e64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Error: CUDA not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 텐서를 다른 장치로 이동\n",
        "tensor_cpu_to_gpu = tensor_cpu.to('cuda')  # CPU에서 GPU로 이동\n",
        "print(tensor_cpu_to_gpu.device)  # cuda:0\n",
        "\n",
        "tensor_gpu_to_cpu = tensor_gpu.to('cpu')  # GPU에서 CPU로 이동\n",
        "print(tensor_gpu_to_cpu.device)  # cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "LDyidBPUtRe-",
        "outputId": "f87d0228-4b23-470e-9305-764d2cf57295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-86ea2ed38cb7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 기존 텐서를 다른 장치로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_cpu_to_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CPU에서 GPU로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_cpu_to_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cuda:0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensor_gpu_to_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# GPU에서 CPU로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 2. How to create the tensor"
      ],
      "metadata": {
        "id": "l7FN9ytvt_Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. non-random values\n",
        "\n",
        "# 1-dim tensor\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# 2-dim tensor\n",
        "y = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(y)\n",
        "print()\n",
        "\n",
        "# 3-dim tensor, every element is 0\n",
        "z = torch.zeros((2, 3, 4))\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "# 4-dim tensor, every element is 1\n",
        "w = torch.ones((2, 2, 2, 2))\n",
        "print(w)\n",
        "print()"
      ],
      "metadata": {
        "id": "abESN7TfvWa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. use the Distribution for random values\n",
        "\n",
        "# case1. Uniform Distribution\n",
        "# create 3 by 2 tensor, each element is randomed between [0, 1)\n",
        "x = torch.rand((3, 2))\n",
        "print(x)\n",
        "\n",
        "# case 2. Normal Distribution\n",
        "# create 2 by 3 tensor, each element is randomed,\n",
        "# following normal distribution, mean = 0 and deviation = 1\n",
        "y = torch.randn((2, 3))\n",
        "print(y)"
      ],
      "metadata": {
        "id": "jWoDyzKmxmVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. randomly-uninitialized values(it is fast because non-intialize)\n",
        "\n",
        "x = torch.empty(2, 3) # default dtype is float32\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "\n",
        "y = torch.empty(2, 3, dtype=torch.int64) # you can use anoter dtype\n",
        "print(y)\n",
        "print(y.dtype)"
      ],
      "metadata": {
        "id": "tQCmICdR2j7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 3. Convet ndarray to tensor by `.from_numpy()` and `.tensor()`\n",
        "**1. 0.**에서는 `.tensor()`를 사용해서 numpy array를 tensor로 변환했다.  \n",
        "`.from_numpy()`로도 변환이 가능한데, 둘의 차이를 알아보자.\n",
        "```\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print(type(x_np), type(x_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```\n",
        "\n",
        "```\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print(type(x_np), type(y_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```"
      ],
      "metadata": {
        "id": "pibQHdZj4_sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `.tensor()`는 call by value 개념이다\n",
        "# 즉 기존의 ndarray를 copy해서 memory에 별도로 생성한다\n",
        "# 따라서 tensor와 ndarray는 서로 독립적이다\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꿔도 ndarray에는 영향을 주지 않는다\n",
        "x_tensor[0] = -1\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysOhzuft7VL_",
        "outputId": "509e9db8-96cd-4200-ccf7-6bc4c14f6d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: 1 tensor: tensor(-1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `.from_numpy()`는 call by reference 개념이다\n",
        "# 이미 ndarray가 할당된 memory adress가 존재할 때,\n",
        "# `.from_numpy()`로 생성된 tensor 객체는 ndarray와 동일한 address를 referencing한다\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꾸면 ndarray에도 영향을 준다\n",
        "y_tensor[0] = -1\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# 반대의 경우에도 마찬가지\n",
        "y_np[1] = -2\n",
        "print('ndarray:', y_np[1], 'tensor:', y_tensor[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCYv34sf8XbU",
        "outputId": "48a7ae73-e764-48f5-f12c-3643310f4985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: -1 tensor: tensor(-1)\n",
            "ndarray: -2 tensor: tensor(-2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 3.(검증) memory address 확인을 통한 검증"
      ],
      "metadata": {
        "id": "L1Be-F_h-xqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음에 내가 아는 선에서 시도한 검증은 다음과 같이 `id()`를 사용하는 것이었다\n",
        "print(id(x_np), id(x_tensor)) # predict: different  | actual: different\n",
        "print(id(y_np), id(y_tensor)) # predict: different  | actual: different"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSj3agKg9TON",
        "outputId": "cfdda378-13c1-4456-9954-b49e6fe76dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134252123634160 134252123617888\n",
            "134255698759280 134252123755904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> numpy와 tensor 모두 memory address에 value 자체를 보관하고, **그 address를 참조하는 객체**를 생성하는 것이다.  \n",
        "\n",
        "> 즉 value 자체의 address와 참조하는 객체의 address 두 가지가 존재하는 상태이다.  \n",
        "이때 `id()`는 후자를 리턴한다.  \n",
        "\n",
        "> (다음 cell) 다음과 같이 **value 자체의 address**를 확인할 수 있다."
      ],
      "metadata": {
        "id": "ynWrjz6h_jpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict: different    | actual: different\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr())\n",
        "print()\n",
        "# predict: same         | actual: same\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8e-XY2I-dKK",
        "outputId": "969d2e08-5070-496e-85d5-7764ba3dd173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97029930612752\n",
            "97030014347648\n",
            "\n",
            "97029930612784\n",
            "97029930612784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 4. Convert tensor to ndarray\n",
        "tensor 객체를 Numpy ndarray로 변환하는 method는 `tensor.numpy()` method 뿐이다.  \n",
        "\n",
        "또한 `tensor.numpy()`는 copy하지 않고, 무조건 share한다."
      ],
      "metadata": {
        "id": "rZACgFWBBhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_npnp = x_tensor.numpy()\n",
        "print(type(x_npnp))\n",
        "\n",
        "y_npnp = y_tensor.numpy()\n",
        "print(type(y_npnp))\n",
        "\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr()) # x_np를 copy한 x_tensor\n",
        "print(x_npnp.__array_interface__['data'][0]) # x_tensor를 share한 x_npnp\n",
        "print()\n",
        "\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr()) # y_np를 share한 y_tensor\n",
        "print(y_npnp.__array_interface__['data'][0]) # y_tensor를 share한 y_npnp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib9mK0z3EAKa",
        "outputId": "771c7ecc-a7c5-4543-e40e-c3d5f47baaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "97029930612752\n",
            "97030014347648\n",
            "97030014347648\n",
            "\n",
            "97029930612784\n",
            "97029930612784\n",
            "97029930612784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. tensor attributes\n",
        "Pytorch의 **tensor object**는 많은 attributes를 갖지만, 그 중에서 자주 쓸 만한 것들에 대해서만 다루겠다.  \n",
        "1. __dtype__\n",
        "    * data type\n",
        "2. __device__\n",
        "    * tensor object가 위치한 device(cpu, gpu)\n",
        "3. __size()__, __shape__\n",
        "    * tensor object의 shape\n",
        "4. __ndim__\n",
        "    * tensor object의 dimension\n",
        "5. __numel()__\n",
        "    * tensor object의 전체 elements 수"
      ],
      "metadata": {
        "id": "y4Max_dxE53G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'dtype', 'device'는 위에서 이미 다뤘으므로 생략함\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "y = x.view(2, 2) # same as reshape in Numpy\n",
        "\n",
        "print(y) # [[1, 2], [3, 4]]\n",
        "print(x.size(), y.size()) # [4] [2, 2] # same as shape in Numpy\n",
        "print(x.shape, y.shape) # ㄴ 그냥 numpy에서 하던 대로 shape 쓰는게 나을 듯 둘이 똑같음\n",
        "print(x.ndim, y.ndim) # 1 2\n",
        "print(x.numel(), y.numel()) # 4 4 # same as size in Numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITA9FadGGdxU",
        "outputId": "11479ba2-ab7a-4c4c-e31b-a66484f12fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([4]) torch.Size([2, 2])\n",
            "torch.Size([4]) torch.Size([2, 2])\n",
            "1 2\n",
            "4 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. tensor calculation\n",
        "Numpy와 마찬가지로 **Broadcasting**이 적용된다."
      ],
      "metadata": {
        "id": "C1iKeN1tQqSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# addition in tensor\n",
        "a = torch.tensor([[1, 2,], [3, 4]])\n",
        "b = torch.tensor([[5, 6], [7, 8]])\n",
        "var_add = a + b\n",
        "print(var_add)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SJbIwaCQ3-D",
        "outputId": "fc1ec81d-a2ad-48c6-f2ed-3da7d8f52fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6,  8],\n",
            "        [10, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# subtraction in tensor\n",
        "var_sub = a - b\n",
        "print(var_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MLiKCNROrx",
        "outputId": "d8e41949-6150-4c23-e58d-765faed8ccb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4, -4],\n",
            "        [-4, -4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply in tensor\n",
        "var_mul = a * b\n",
        "print(var_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11E85enDRxva",
        "outputId": "253da369-c039-46c7-fd88-c0c543155722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5, 12],\n",
            "        [21, 32]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide in tensor\n",
        "var_div = a / b\n",
        "print(var_div)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0hBCwF_vJe0",
        "outputId": "ffac16d9-0113-4990-dc08-c6503da23b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, particularly in linear algebra, matrix multiplication is a binary operation that produces a matrix from two matrices. For matrix multiplication, **the number of columns in the first matrix** must be equal to **the number of rows in the second matrix**. The resulting matrix, known as the matrix product, has **the number of rows of the first** and **the number of columns of the second** matrix. The product of matrices A and B is denoted as AB.  \n",
        "* $C_{11} = A.row_1 * B.col_1$\n",
        "* $C_{12} = A.row_1 * B.col_2$\n",
        "* $C_{21} = A.row_2 * B.col_1$\n",
        "* $C_{22} = A.row_2 * B.col_2$"
      ],
      "metadata": {
        "id": "2pjvDp8cxVUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication\n",
        "var_matrix_mul = torch.mm(a, b)\n",
        "print(var_matrix_mul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH7kdxk1vjto",
        "outputId": "0ff2e56f-f45b-4caa-d2ab-ea94a3ef2b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, the dot product or scalar product is an algebraic operation that **takes two equal-length sequences of numbers** (usually coordinate vectors), and **returns a single number**. It is often called the inner product."
      ],
      "metadata": {
        "id": "R3nyTxlczpjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dot product in tensor\n",
        "var_dot_prod = torch.dot(a[0], a[1])\n",
        "print(var_dot_prod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvCd0Kc6vjzo",
        "outputId": "a8653a42-21fd-4241-d471-04172cf896e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max value\n",
        "#                  col1    col2\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "b = torch.tensor([[4, 3], [2, 1]])\n",
        "var_max_a = torch.max(a)\n",
        "var_max_b = torch.max(b)\n",
        "var_max_ab = torch.max(a, b)\n",
        "print(var_max_a, var_max_b) # 4 4\n",
        "# column끼리 비교해서 max를 리턴함\n",
        "# max_col1, max_col2\n",
        "print(var_max_ab) # [4, 3], [3, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quuNPJ1I0KfI",
        "outputId": "7cd68536-7523-4e4f-f1d8-7e3b76d1d572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4) tensor(4)\n",
            "tensor([[4, 3],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensionality reduction; 차원 축소\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# dim=0, 하나의 matrix의 각 row를 개별 matrix로 취급하여 dot product를 수행하는 개념\n",
        "var_reduce_dim0 = torch.sum(a, dim=0)\n",
        "# dim=1\n",
        "var_reduce_dim1 = torch.sum(a, dim=1)\n",
        "\n",
        "print(var_reduce_dim0)\n",
        "print(var_reduce_dim1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2xVK-e-1d_q",
        "outputId": "7e599fe7-6de3-4b3e-8fb0-deb865a8e853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 6])\n",
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose\n",
        "a = torch.tensor([[1, 2], [3, 4]])\n",
        "# parameter is input tensor, first dim and second dim to transposed\n",
        "var_trans = torch.transpose(a, 0, 1)\n",
        "print(var_trans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk_3fp5m2mVq",
        "outputId": "9ac06629-ac90-47bb-8195-3e27ee0eb998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 3],\n",
            "        [2, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing\n",
        "#                   0       1       2\n",
        "#                  0  1    0  1    0  1\n",
        "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "var_index = a[1, 0]\n",
        "print(var_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6G94DUj3m33",
        "outputId": "83b0a397-96c9-4f45-a2ba-57d7a86ea142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "var_slice_1 = a[:, :1] # for the all rows, col1 전까지\n",
        "             # '까지'니까 selected element가 1개라는 것이 보장되지 않음\n",
        "             # 따라서 2dim으로 리턴\n",
        "var_slice_2 = a[:, 1] # for the all rows, col1만\n",
        "            # '만'이니까 selected element가 1개라는 것이 보장됨\n",
        "            # 따라서 1dim으로 리턴\n",
        "print(var_slice_1)\n",
        "print(var_slice_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoKXSINZ4AMf",
        "outputId": "35318939-c37f-4d60-910f-3f24f25234d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [3],\n",
            "        [5]])\n",
            "tensor([2, 4, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boolean indexing\n",
        "a = torch.tensor([1, 2, 3, 4, 5])\n",
        "# statement 만족하면 True, 아니면 False가 되고 True인 index의 elements만 리턴\n",
        "var_bool = a[a > 3]\n",
        "print(var_bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc1QK6dE5WUa",
        "outputId": "478c54f9-4a17-4bfd-e0e9-e4b03f92bb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] [머신러닝 파이토치 다루기 기초 - WikiDocs](https://wikidocs.net/book/9379)  \n",
        "[2] [PyTorch Tensor vs NumPy Array - GeeksforGeeks](https://www.geeksforgeeks.org/pytorch-tensor-vs-numpy-array/)  \n",
        "[3] [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)  "
      ],
      "metadata": {
        "id": "RydV314IFN30"
      }
    }
  ]
}