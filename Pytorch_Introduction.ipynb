{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ANng_D3WI0dP",
        "pIpjnr_OKcXM",
        "mpTv64UyUl-U",
        "l7FN9ytvt_Mo"
      ],
      "authorship_tag": "ABX9TyMLMl7Xu29SayxmFGKrxS35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudevico/Gachon-AISTUDY/blob/main/Pytorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. tensor data type\n",
        "* 기본적으로 Machine Learning에서는 연산 속도를 위해서 array data type을 사용한다.\n",
        "* 이때 Numpy에서는 CPU를 사용하여 array를 연산하기 때문에 DL 수준의 dataset에 대해서 연산하기에는 시간이 많이 소요된다.\n",
        "* Tensor는 GPU 연산을 지원하는 array이다. pytorch에서는 이를 사용한다.  \n",
        "\n",
        "> 왜 Numpy ndarray가 아닌, Pytorch tensor를 사용하는지에 대한 자세한 이유들은 이후 실습 과정을 통해서 자연스럽게 알 수 있을 것으로 판단된다."
      ],
      "metadata": {
        "id": "ANng_D3WI0dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 0. Convert list(python) or ndarray(numpy) to tensor(pytorch)\n",
        "\n",
        "cf. [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)\n",
        "\n",
        "```\n",
        "torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
        "```\n",
        "\n",
        "**Parameters**  \n",
        "* __data__ - Can be a list, tuple, Numpy `ndarray`, scalar, ...  \n",
        "\n",
        "**Keyword Arguements**  \n",
        "* __dtype__(`torch.dtype`, optinal) - the desired data type of returned tensor. default라면, 원본 데이터 타입\n",
        "* __device__(`torch.device`, optional) - the device of the constructed tensor. defalut라면, 'cpu' 사용, 'cuda'로 설정 시 gpu 사용 가능.\n",
        "* __requires_grad__(_bool_, optional)\n",
        "* **pin_memory**(*bool*, optional)"
      ],
      "metadata": {
        "id": "pIpjnr_OKcXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# case1-1. python list_int\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_default = torch.tensor(data)\n",
        "x_int = torch.tensor(data, dtype=int)\n",
        "x_int64 = torch.tensor(data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int ßßdata type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5m9i8faGUA-",
        "outputId": "cfd0cd25-4002-42d2-bf1b-6c5fb4dee365"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case1-2. python list_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(data, dtype=float)\n",
        "x_float32 = torch.tensor(data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(data, dtype=torch.float64)\n",
        "x_double = torch.tensor(data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI5yDY6SRf4",
        "outputId": "dd182ad0-6790-4070-dbfa-8c55dbfa2852"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2. numpy to tensor\n",
        "# 결론적으로는 list to tensor나 ndarray to tensor나 동일하다.\n",
        "import numpy as np\n",
        "np_data = np.array(data)\n",
        "print(type(np_data))\n",
        "print(np_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBreb74oTSDe",
        "outputId": "f39cbc21-c4b7-4dd7-ddcb-6c3aa9b092ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-1. numpy ndarray_int\n",
        "x_default = torch.tensor(np_data)\n",
        "x_int = torch.tensor(np_data, dtype=int)\n",
        "x_int64 = torch.tensor(np_data, dtype=torch.int64) # default int\n",
        "x_int32 = torch.tensor(np_data, dtype=torch.int32)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 64bit로 한다\n",
        "print(x_default.dtype)\n",
        "print(x_int.dtype)\n",
        "print(x_int64.dtype)\n",
        "print(x_int32.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_default)    # default -> no return\n",
        "print(x_int)        # default -> no return\n",
        "print(x_int64)      # default -> no return\n",
        "print(x_int32)      # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVc_mJQ5T75Z",
        "outputId": "fb9200ff-97f9-46b7-909b-4682191a23d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.int64\n",
            "torch.int64\n",
            "torch.int32\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case2-2. numpy ndarray_float\n",
        "data = [[1, 2, 3], [4, 5, 6]]\n",
        "\n",
        "x_float = torch.tensor(np_data, dtype=float)\n",
        "x_float32 = torch.tensor(np_data, dtype=torch.float32) # default float\n",
        "x_float64 = torch.tensor(np_data, dtype=torch.float64)\n",
        "x_double = torch.tensor(np_data, dtype=torch.double)\n",
        "\n",
        "# pytorch에서는 int data type의 default를 32bit로 한다\n",
        "print(x_float.dtype)\n",
        "print(x_float32.dtype) # default float\n",
        "print(x_float64.dtype)\n",
        "print(x_double.dtype)\n",
        "\n",
        "# pytorch에서는 tensor의 data type이 default가 아닌 경우에만 return한다\n",
        "print(x_float)      # not default -> return\n",
        "print(x_float32)    # default -> no return\n",
        "print(x_float64)    # not default -> return\n",
        "print(x_double)     # not default -> return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ipKbkVUK1g",
        "outputId": "b9a3d1a1-3547-4da1-a832-d4d4ba8429b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n",
            "torch.float32\n",
            "torch.float64\n",
            "torch.float64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 1. How to use GPU(CUDA)"
      ],
      "metadata": {
        "id": "mpTv64UyUl-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch를 실행중인 device에서 cuda(gpu)를 사용할 수 있는지 확인\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uiGPsRvIpfH",
        "outputId": "e50cebcc-6eb9-48c5-adc9-9e9985cf1652"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.tensor() 등으로 tensor를 생성할 때는 default로 'cpu'를 사용\n",
        "print(x_default.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogrRdUj0QKq7",
        "outputId": "1a0f15b8-8685-431f-8e6f-ab31236be9cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU에 텐서 생성 (default)\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0]) # same as the below\n",
        "tensor_cpu = torch.tensor([1.0, 2.0, 3.0], device='cpu') # same as the above\n",
        "print(tensor_cpu.device) # cpu\n",
        "\n",
        "# GPU에 텐서 생성 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(tensor_gpu.device)  # cuda:0\n",
        "else:\n",
        "    print('Error: CUDA not available')"
      ],
      "metadata": {
        "id": "OUDAKK0sVV3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75961584-8e97-4fcc-e776-92894dcb90e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 텐서를 다른 장치로 이동\n",
        "tensor_cpu_to_gpu = tensor_cpu.to('cuda')  # CPU에서 GPU로 이동\n",
        "print(tensor_cpu_to_gpu.device)  # cuda:0\n",
        "\n",
        "tensor_gpu_to_cpu = tensor_gpu.to('cpu')  # GPU에서 CPU로 이동\n",
        "print(tensor_gpu_to_cpu.device)  # cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDyidBPUtRe-",
        "outputId": "fe4761dd-3b73-436d-f3a7-00c2809474de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 2. How to create the tensor"
      ],
      "metadata": {
        "id": "l7FN9ytvt_Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. non-random values\n",
        "\n",
        "# 1-dim tensor\n",
        "x = torch.tensor([1, 2, 3])\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# 2-dim tensor\n",
        "y = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print(y)\n",
        "print()\n",
        "\n",
        "# 3-dim tensor, every element is 0\n",
        "z = torch.zeros((2, 3, 4))\n",
        "print(z)\n",
        "print()\n",
        "\n",
        "# 4-dim tensor, every element is 1\n",
        "w = torch.ones((2, 2, 2, 2))\n",
        "print(w)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abESN7TfvWa6",
        "outputId": "e3931db3-5cea-4c18-c8b6-c2210c8502b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]])\n",
            "\n",
            "tensor([[[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. use the Distribution for random values\n",
        "\n",
        "# case1. Uniform Distribution\n",
        "# create 3 by 2 tensor, each element is randomed between [0, 1)\n",
        "x = torch.rand((3, 2))\n",
        "print(x)\n",
        "\n",
        "# case 2. Normal Distribution\n",
        "# create 2 by 3 tensor, each element is randomed,\n",
        "# following normal distribution, mean = 0 and deviation = 1\n",
        "y = torch.randn((2, 3))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWoDyzKmxmVp",
        "outputId": "68cb0c22-cb93-4dbd-d9cf-3d6fb4f0dba8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5009, 0.5212],\n",
            "        [0.6158, 0.0122],\n",
            "        [0.7949, 0.5782]])\n",
            "tensor([[ 1.9408,  1.0380,  1.5457],\n",
            "        [-0.7952, -0.2599, -0.0132]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. randomly-uninitialized values(it is fast because non-intialize)\n",
        "\n",
        "x = torch.empty(2, 3) # default dtype is float32\n",
        "print(x)\n",
        "print(x.dtype)\n",
        "\n",
        "y = torch.empty(2, 3, dtype=torch.int64) # you can use anoter dtype\n",
        "print(y)\n",
        "print(y.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQCmICdR2j7y",
        "outputId": "8f2e0368-f3f2-4df4-c80d-2c95ab47a511"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0125e-24,  4.5825e-41, -8.3521e-31],\n",
            "        [ 3.1124e-41,  0.0000e+00,  0.0000e+00]])\n",
            "torch.float32\n",
            "tensor([[     95412690159632,   36028797018963968,      95397799394072],\n",
            "        [          536870912,   21767388716337664, 7236722170925376883]])\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 3. Convet ndarray to tensor by `.from_numpy()` and `.tensor()`\n",
        "**1. 0.**에서는 `.tensor()`를 사용해서 numpy array를 tensor로 변환했다.  \n",
        "`.from_numpy()`로도 변환이 가능한데, 둘의 차이를 알아보자.\n",
        "```\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print(type(x_np), type(x_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```\n",
        "\n",
        "```\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print(type(x_np), type(y_tensor))\n",
        "\n",
        "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
        "```"
      ],
      "metadata": {
        "id": "pibQHdZj4_sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `.tensor()`는 call by value 개념이다\n",
        "# 즉 기존의 ndarray를 copy해서 memory에 별도로 생성한다\n",
        "# 따라서 tensor와 ndarray는 서로 독립적이다\n",
        "x_np = np.array([1, 2, 3])\n",
        "x_tensor = torch.tensor(x_np)\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꿔도 ndarray에는 영향을 주지 않는다\n",
        "x_tensor[0] = -1\n",
        "print('ndarray:', x_np[0], 'tensor:', x_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysOhzuft7VL_",
        "outputId": "aaebec31-58eb-4036-8bb0-d6348d3bec0f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: 1 tensor: tensor(-1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `.from_numpy()`는 call by reference 개념이다\n",
        "# 이미 ndarray가 할당된 memory adress가 존재할 때,\n",
        "# `.from_numpy()`로 생성된 tensor 객체는 ndarray와 동일한 address를 referencing한다\n",
        "y_np = np.array([1, 2, 3])\n",
        "y_tensor = torch.from_numpy(y_np)\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# tesnor의 element를 바꾸면 ndarray에도 영향을 준다\n",
        "y_tensor[0] = -1\n",
        "print('ndarray:', y_np[0], 'tensor:', y_tensor[0])\n",
        "\n",
        "# 반대의 경우에도 마찬가지\n",
        "y_np[1] = -2\n",
        "print('ndarray:', y_np[1], 'tensor:', y_tensor[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCYv34sf8XbU",
        "outputId": "59ec9ea7-ece8-48c4-ef20-5da9ee700268"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ndarray: 1 tensor: tensor(1)\n",
            "ndarray: -1 tensor: tensor(-1)\n",
            "ndarray: -2 tensor: tensor(-2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 3.(검증) memory address 확인을 통한 검증"
      ],
      "metadata": {
        "id": "L1Be-F_h-xqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음에 내가 아는 선에서 시도한 검증은 다음과 같이 `id()`를 사용하는 것이었다\n",
        "print(id(x_np), id(x_tensor)) # predict: different  | actual: different\n",
        "print(id(y_np), id(y_tensor)) # predict: different  | actual: different"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSj3agKg9TON",
        "outputId": "71eef73d-2fe5-4bf5-a180-58eee3c9344e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140451603101712 140451603761728\n",
            "140451603101520 140451602993920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> numpy와 tensor 모두 memory address에 value 자체를 보관하고, **그 address를 참조하는 객체**를 생성하는 것이다.  \n",
        "\n",
        "> 즉 value 자체의 address와 참조하는 객체의 address 두 가지가 존재하는 상태이다.  \n",
        "이때 `id()`는 후자를 리턴한다.  \n",
        "\n",
        "> (다음 cell) 다음과 같이 **value 자체의 address**를 확인할 수 있다."
      ],
      "metadata": {
        "id": "ynWrjz6h_jpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict: different    | actual: different\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr())\n",
        "print()\n",
        "# predict: same         | actual: same\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8e-XY2I-dKK",
        "outputId": "ec93eef7-e5ce-4123-ee6a-2247437d239e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95397797441568\n",
            "95397893097600\n",
            "\n",
            "95397882517744\n",
            "95397882517744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 4. Convert tensor to ndarray\n",
        "tensor 객체를 Numpy ndarray로 변환하는 method는 `tensor.numpy()` method 뿐이다.  \n",
        "\n",
        "또한 `tensor.numpy()`는 copy하지 않고, 무조건 share한다."
      ],
      "metadata": {
        "id": "rZACgFWBBhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_npnp = x_tensor.numpy()\n",
        "print(type(x_npnp))\n",
        "\n",
        "y_npnp = y_tensor.numpy()\n",
        "print(type(y_npnp))\n",
        "\n",
        "print(x_np.__array_interface__['data'][0])\n",
        "print(x_tensor.data_ptr()) # x_np를 copy한 x_tensor\n",
        "print(x_npnp.__array_interface__['data'][0]) # x_tensor를 share한 x_npnp\n",
        "print()\n",
        "\n",
        "print(y_np.__array_interface__['data'][0])\n",
        "print(y_tensor.data_ptr()) # y_np를 share한 y_tensor\n",
        "print(y_npnp.__array_interface__['data'][0]) # y_tensor를 share한 y_npnp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib9mK0z3EAKa",
        "outputId": "1290ac1c-c50c-48fa-d791-ae732cf76171"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "95397797441568\n",
            "95397893097600\n",
            "95397893097600\n",
            "\n",
            "95397882517744\n",
            "95397882517744\n",
            "95397882517744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. tensor attributes\n",
        "Pytorch의 **tensor object**는 많은 attributes를 갖지만, 그 중에서 자주 쓸 만한 것들에 대해서만 다루겠다.  \n",
        "1. __dtype__\n",
        "    * data type\n",
        "2. __device__\n",
        "    * tensor object가 위치한 device(cpu, gpu)\n",
        "3. __size__\n",
        "    * tensor object의 shape\n",
        "4. __ndim__\n",
        "    * tensor object의 dimension\n",
        "5. __numel()__\n",
        "    * tensor object의 전체 elements 수"
      ],
      "metadata": {
        "id": "y4Max_dxE53G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'dtype', 'device'는 위에서 이미 다뤘으므로 생략함\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "y = x.view(2, 2) # same as reshape in Numpy\n",
        "\n",
        "print(y) # [[1, 2], [3, 4]]\n",
        "print(x.size(), y.size()) # [4] [2, 2] # same as shape in Numpy\n",
        "print(x.ndim, y.ndim) # 1 2\n",
        "print(x.numel(), y.numel()) # 4 4 # same as size in Numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITA9FadGGdxU",
        "outputId": "347816ee-1aa2-4bb1-fe7b-ac36a9d78f13"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([4]) torch.Size([2, 2])\n",
            "1 2\n",
            "4 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] [머신러닝 파이토치 다루기 기초 - WikiDocs](https://wikidocs.net/book/9379)  \n",
        "[2] [PyTorch Tensor vs NumPy Array - GeeksforGeeks](https://www.geeksforgeeks.org/pytorch-tensor-vs-numpy-array/)  \n",
        "[3] [torch.tensor — PyTorch 2.4 documentation](https://pytorch.org/docs/stable/generated/torch.tensor.html)  "
      ],
      "metadata": {
        "id": "RydV314IFN30"
      }
    }
  ]
}